{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d019ceb-2b2f-4d1a-a0af-c6dbf2acae0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241725b-4e62-4a4d-8eab-4b7bcb0e9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_swiss_roll\n",
    "import sklearn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pl.seed_everything(1)\n",
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2*hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim * 2)  # Mean and log-variance\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2 * hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mean, logvar = h.chunk(2, dim=-1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        return self.decode(z), z, mean, logvar\n",
    "\n",
    "# Loss function\n",
    "def vae_loss(recon_x, x, mean, logvar, beta=0.01, score=None, DSM=None):\n",
    "    if isinstance(recon_x, list) and isinstance(recon_x, list):\n",
    "        for i in range(len(recon_x)):\n",
    "            if i == 0:\n",
    "                recon_loss = nn.functional.mse_loss(recon_x[i], x[i], reduction='sum')\n",
    "            else:\n",
    "                recon_loss += nn.functional.mse_loss(recon_x[i], x[i], reduction='sum')\n",
    "    else:\n",
    "        recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    kld_encoder_posterior = 0.5 * torch.sum(- 1 - logvar)\n",
    "    kld_prior = 0.5 * torch.sum(mean.pow(2) + logvar.exp())\n",
    "    kld_loss = kld_encoder_posterior + kld_prior\n",
    "    if score is not None and DSM is None:\n",
    "        kld_loss = kld_encoder_posterior - score\n",
    "    elif DSM is not None:\n",
    "        kld_loss = kld_encoder_posterior + DSM\n",
    "    return recon_loss + beta * kld_loss, recon_loss, kld_encoder_posterior, kld_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80788b-a663-46cb-ba80-663bf7f08a6d",
   "metadata": {},
   "source": [
    "#### CNN VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6239897-f4ce-400a-ab17-f431e5bd6839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=4, stride=2, padding=1)  # Output: 32x14x14\n",
    "        self.conv2 = nn.Conv2d(4, 16, kernel_size=4, stride=2, padding=1) # Output: 64x7x7\n",
    "        self.conv3 = nn.Conv2d(16, 64, kernel_size=3, stride=2, padding=1) # Output: 128x4x4\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n",
    "        self.fc2_mu = nn.Linear(256, 1 * 16 * 16)\n",
    "        self.fc2_logvar = nn.Linear(256, 1 * 16 * 16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = self.fc2_mu(x)\n",
    "        logvar = self.fc2_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(256, 64 * 7 * 7)  # Adjusted to match the size before reshaping\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 16, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.deconv3 = nn.ConvTranspose2d(4, 1, kernel_size=4, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(56*56, 28*28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = x.view(x.size(0), 64, 7, 7)  # Reshape to match the size before upsampling\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = F.relu(self.deconv3(x)).view((x.shape[0], -1))\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "        \n",
    "class CNN_VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_VAE, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        # print(f'recon: {recon.shape}')\n",
    "        return recon.view((z.shape[0], -1)), z.view((z.shape[0], -1)), mu.view((z.shape[0], -1)), logvar.view((z.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44125135-5009-4c42-b4c4-2a2330038d97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf82cc-daa3-4b14-8ced-a61037e37439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, out_dim)\n",
    "        self.ln1 = nn.LayerNorm(out_dim)\n",
    "        self.swish = nn.SiLU()\n",
    "        self.fc2 = nn.Linear(out_dim, out_dim)\n",
    "        self.ln2 = nn.LayerNorm(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.swish(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out += identity  # Skip connection\n",
    "        return self.swish(out)\n",
    "\n",
    "# UNet with advanced techniques\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_timesteps, embedding_dim=2, multiplier=4, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), is_warm_init=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.device = device\n",
    "\n",
    "        # Define encoder layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim, multiplier*in_dim),\n",
    "            nn.SiLU(),\n",
    "            ResidualBlock(multiplier*in_dim, multiplier*in_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            ResidualBlock(multiplier*in_dim, multiplier*in_dim),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        # Define decoder layers\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(multiplier*in_dim + embedding_dim, multiplier*in_dim),\n",
    "            nn.SiLU(),\n",
    "            ResidualBlock(multiplier*in_dim, multiplier*in_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            ResidualBlock(multiplier*in_dim, multiplier*in_dim),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(multiplier*in_dim, out_dim)\n",
    "        )\n",
    "\n",
    "        # Define time step embedding layer for decoder\n",
    "        self.embedding = nn.Embedding(num_timesteps, embedding_dim)\n",
    "\n",
    "        if is_warm_init:\n",
    "            self.warm_init()\n",
    "\n",
    "    def forward(self, x, timestep, enc_sigma=None):\n",
    "        # Encoder\n",
    "        if enc_sigma is not None:\n",
    "            encoded_enc_sigma = self.encoder(enc_sigma)\n",
    "        else:\n",
    "            encoded_enc_sigma = 0\n",
    "        x = self.encoder(x) + encoded_enc_sigma\n",
    "\n",
    "        # Decoder\n",
    "        x = self.decoder(torch.hstack((x, self.embedding(timestep))))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def warm_init(self):\n",
    "        # Custom initialization for better convergence\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e61a283-addc-4cca-a765-f69e7fe220ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Score-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7845cc-18ce-4662-93fa-d9484d992726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMA:\n",
    "    def __init__(self, model, decay):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = self._clone_model_params()\n",
    "\n",
    "    def _clone_model_params(self):\n",
    "        shadow = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                shadow[name] = param.data.clone()\n",
    "        return shadow\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "class Score_fn(nn.Module):\n",
    "    def __init__(self, model, ema=None, ema_decay=0.99, sigma_min=0.01, sigma_max=50, num_timesteps=1000, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        \"\"\"Construct a score function model.\n",
    "        \n",
    "        Args:\n",
    "          sigma_min: smallest sigma.\n",
    "          sigma_max: largest sigma.\n",
    "          num_timestep: number of discretization steps\n",
    "        \"\"\"\n",
    "        super(Score_fn, self).__init__()\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "        self.discrete_sigma = torch.exp(torch.linspace(np.log(self.sigma_min), np.log(self.sigma_max), num_timesteps)).to(device)\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.loss_dict = {}\n",
    "        self.total_loss = 0\n",
    "        self.loss_counter = 0\n",
    "        if ema is not None:\n",
    "            self.ema = ema(model, decay=ema_decay)\n",
    "\n",
    "        # Learnable parameter for residual score function and assures value between [0,1]\n",
    "        self.lbda = nn.ParameterList([nn.Parameter(torch.tensor([0.0]))])\n",
    "\n",
    "    def to_device(self):\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "    # Compute denoising score matching loss\n",
    "    def compute_DSM_loss(self, x, t, enc_mu=None, enc_sigma=None, alpha=None, turn_off_enc_sigma=False, learn_lbda=False, is_mixing=False, is_residual=False, is_vanilla=False, is_LSGM=False, divide_by_sigma=False):\n",
    "        sigmas = self.discrete_sigma[t.long()].view(x.shape[0], *([1] * len(x.shape[1:])))\n",
    "        noise = torch.randn_like(x, device=self.device) * sigmas\n",
    "        perturbed_data = x + noise\n",
    "        if is_mixing:\n",
    "            score = self.get_mixing_score_fn(perturbed_data, t, alpha=alpha, is_residual=is_residual, is_vanilla=is_vanilla, divide_by_sigma=divide_by_sigma)\n",
    "        elif is_residual:\n",
    "            enc_eps = x - enc_mu\n",
    "            score = self.get_residual_score_fn(perturbed_data, t, enc_eps, enc_sigma, turn_off_enc_sigma, learn_lbda, is_vanilla=is_vanilla, divide_by_sigma=divide_by_sigma)\n",
    "        else:\n",
    "            score = self.get_score_fn(perturbed_data, t)\n",
    "        target = -noise / (sigmas ** 2)\n",
    "        losses = torch.square(score - target)\n",
    "        losses = 1/2. * torch.sum(losses.reshape(losses.shape[0], -1), dim=-1) * sigmas.squeeze() ** 2\n",
    "        if is_LSGM:\n",
    "            return torch.sum(losses)\n",
    "        else:\n",
    "            return torch.mean(losses)\n",
    "\n",
    "    # Get score function\n",
    "    def get_score_fn(self, x, t, detach=False):\n",
    "        if detach:\n",
    "            self.model.eval()\n",
    "            return (self.model(x, t) / self.discrete_sigma[t.long()].view(x.shape[0], *([1] * len(x.shape[1:])))).detach()\n",
    "        else:\n",
    "            return self.model(x, t) / self.discrete_sigma[t.long()].view(x.shape[0], *([1] * len(x.shape[1:])))\n",
    "\n",
    "    # Our implementation of residual score function\n",
    "    def get_residual_score_fn(self, x, t, enc_eps, enc_sigma, detach=False, turn_off_enc_sigma=False, learn_lbda=False):\n",
    "\n",
    "        # turn on eval for detach\n",
    "        if detach:\n",
    "            self.model.eval()\n",
    "        \n",
    "        # Computes learnable score\n",
    "        learnable_score = self.model(x, t) / self.discrete_sigma[t.long()].view(x.shape[0], *([1] * len(x.shape[1:])))\n",
    "\n",
    "        # Learns lbda hyperparameter\n",
    "        if learn_lbda:\n",
    "            learnable_score = self.lbda * learnable_score\n",
    "\n",
    "        # Makes the variance equal 1 when turned off and variance equal to the encoder variance\n",
    "        if turn_off_enc_sigma:\n",
    "            residual_score = - enc_eps\n",
    "        else:\n",
    "            residual_score = - enc_eps / (enc_sigma ** 2)\n",
    "        if detach:\n",
    "            self.model.train()\n",
    "            return (learnable_score + residual_score).detach()\n",
    "        else:\n",
    "            return learnable_score + residual_score\n",
    "\n",
    "    # Training LSGM Mixing Normal and Neural Score Functions based on this paper https://arxiv.org/pdf/2106.05931\n",
    "    # if no alpha param is given assumed alpha is learned by the model. If it is residual behaves like Prof. Inouye's idea\n",
    "    def get_mixing_score_fn(self, x, t, alpha=None, is_residual=False, is_vanilla=False, detach=False, divide_by_sigma=False):\n",
    "\n",
    "        if detach:\n",
    "            self.model.eval()\n",
    "\n",
    "        # Converts lbda to alpha to match LGSM notation and bounds [0, 1]\n",
    "        if alpha is None:\n",
    "            # alpha = torch.relu(torch.tanh(self.lbda[0]))\n",
    "            alpha = torch.sigmoid(self.lbda[0])\n",
    "            # print(f\"alpha: {alpha}\")\n",
    "        else:\n",
    "            alpha = alpha.to(self.device)\n",
    "\n",
    "        if divide_by_sigma:\n",
    "            learnable_score = alpha * self.model(x, t) / self.discrete_sigma[t.long()].view(x.shape[0], *([1] * len(x.shape[1:])))\n",
    "        else:\n",
    "            learnable_score = alpha * self.model(x, t)\n",
    "\n",
    "        # Turning on the residual flag is identical to Prof. Inouye's method\n",
    "        if is_residual:\n",
    "            residual_score = - x\n",
    "        else:\n",
    "            residual_score = - (1 - alpha) * x\n",
    "\n",
    "        if detach:\n",
    "            if is_vanilla:\n",
    "                return learnable_score.detach()\n",
    "            self.model.train()\n",
    "            return (learnable_score + residual_score).detach()\n",
    "        else:\n",
    "            if is_vanilla:\n",
    "                return learnable_score\n",
    "            return learnable_score + residual_score\n",
    "\n",
    "\n",
    "    def get_LSGM_loss(self, x, t=None, is_mixing=False, is_residual=False, is_vanilla=False, alpha=None):\n",
    "        if t is None:\n",
    "            t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=device)\n",
    "        \n",
    "        loss = self.compute_DSM_loss(x, t, is_mixing=is_mixing, is_residual=is_residual, alpha=alpha, is_vanilla=is_vanilla, is_LSGM=True, divide_by_sigma=True)\n",
    "        return loss\n",
    "\n",
    "    # Update one batch and add shrink the max timestep for reducing the variance range of training (default is equal to defined num_timestep).\n",
    "    # When verbose is true, gets the average loss up until last verbose and saves to loss dict\n",
    "    def update_score_fn(self, x, optimizer, alpha=None, max_timestep=None, t=None, verbose=False, is_mixing=False, is_residual=False, is_vanilla=False, divide_by_sigma=False):\n",
    "        # TODO: Add ema optimization\n",
    "        if max_timestep is None or max_timestep > self.num_timesteps:\n",
    "            max_timestep = self.num_timesteps\n",
    "\n",
    "        if t is None:\n",
    "            t = torch.randint(0, max_timestep, (x.shape[0],), device=device)\n",
    "        \n",
    "        loss = self.compute_DSM_loss(x, t, is_mixing=is_mixing, is_residual=is_residual, alpha=alpha, is_vanilla=is_vanilla, divide_by_sigma=False)\n",
    "\n",
    "        self.total_loss += loss.item()\n",
    "        self.loss_counter += 1.\n",
    "        if verbose:\n",
    "            avg_loss = self.total_loss / self.loss_counter\n",
    "            self.reset_loss_count()\n",
    "            self.update_loss_dict(avg_loss)\n",
    "            print(avg_loss)\n",
    "            print(f'alpha: {torch.sigmoid(self.lbda[0])}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update EMA\n",
    "        if hasattr(self, 'ema'):\n",
    "            self.ema.update()\n",
    "            \n",
    "    # Update for residual score model training\n",
    "    def update_residual_score_fn(self, x, enc_mu, enc_sigma, optimizer, max_timestep=None, learn_lbda=False, turn_off_enc_sigma=False, t=None, verbose=False):\n",
    "        if max_timestep is None or max_timestep > self.num_timesteps:\n",
    "            max_timestep = self.num_timesteps\n",
    "        \n",
    "        if t is None:\n",
    "            t = torch.randint(0, max_timestep, (x.shape[0],), device=device)\n",
    "        \n",
    "        loss = self.compute_DSM_loss(x, t, is_residual=True, enc_mu=enc_mu, enc_sigma=enc_sigma, turn_off_enc_sigma=turn_off_enc_sigma, learn_lbda=learn_lbda)\n",
    "\n",
    "        self.total_loss += loss.item()\n",
    "        self.loss_counter += 1.\n",
    "        if verbose:\n",
    "            avg_loss = self.total_loss / self.loss_counter\n",
    "            self.reset_loss_count()\n",
    "            self.update_loss_dict(avg_loss)\n",
    "            print(avg_loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update EMA\n",
    "        if hasattr(self, 'ema'):\n",
    "            self.ema.update()\n",
    "\n",
    "    def add_EMA_training(self, ema, decay=0.99):\n",
    "        self.ema = ema(self.model, decay)\n",
    "\n",
    "    def update_param_with_EMA(self):\n",
    "        if hasattr(self, 'ema'):\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if param.requires_grad and name in self.ema.shadow:\n",
    "                    param.data.copy_(self.ema.shadow[name])\n",
    "        else:\n",
    "            raise AttributeError(\"EMA model is not defined in the class. Please use add_EMA_training class function and retrain\")\n",
    "        \n",
    "    # Draws a vector field of the score function\n",
    "    def draw_gradient_field(self, xlim, ylim, t=0, x_num=20, y_num=20, file=\"./Score_Function\", noise_label=1, save=False, data=None, labels=None, n_samples=100, alpha=None, is_mixture=False, is_residual=False, is_vanilla=False):\n",
    "        x, y = np.meshgrid(np.linspace(xlim[0], xlim[1], x_num), np.linspace(ylim[0], ylim[1], y_num))\n",
    "        x_ = torch.from_numpy(x.reshape(-1, 1)).type(torch.float).to(self.device)\n",
    "        y_ = torch.from_numpy(y.reshape(-1, 1)).type(torch.float).to(self.device)\n",
    "    \n",
    "        input = torch.hstack((x_, y_))\n",
    "\n",
    "        if data is not None:\n",
    "            if isinstance(data, torch.Tensor):\n",
    "                data = data.detach()\n",
    "                if data.is_cuda:\n",
    "                    data = data.cpu().numpy()\n",
    "            else:\n",
    "                return data\n",
    "\n",
    "            if labels is not None:\n",
    "                data1, data2 = data.chunk(2)\n",
    "                labels1, labels2 = labels.view((-1,)).chunk(2)\n",
    "                data1_l1, data1_l2 = data1[labels1==0], data1[labels1==1]\n",
    "                data2_l1, data2_l2 = data2[labels2==0], data2[labels1==1]\n",
    "                plt.scatter(data1_l1[:n_samples, 0], data1_l1[:n_samples, 1], marker='x', label='D1_L1', c='b', s=20)\n",
    "                plt.scatter(data1_l2[:n_samples, 0], data1_l2[:n_samples, 1], marker='o', label='D1_L2', c='b', s=20)\n",
    "                plt.scatter(data2_l1[:n_samples, 0], data2_l1[:n_samples, 1], marker='+', label='D2_L1', c='g', s=20)\n",
    "                plt.scatter(data2_l2[:n_samples, 0], data2_l2[:n_samples, 1], marker='o', label='D2_L2', c='g', s=20)\n",
    "                plt.legend()\n",
    "            else:\n",
    "                plt.scatter(data[:, 0], data[:, 1])\n",
    "\n",
    "        if is_mixture:\n",
    "            score_fn = self.get_mixing_score_fn(input, torch.ones((x_num * y_num,), device=device).type(torch.long) * t, detach=True, alpha=alpha, is_vanilla=is_vanilla)\n",
    "        elif is_residual:\n",
    "            score_fn = self.get_mixing_score_fn(input, torch.ones((x_num * y_num,), device=device).type(torch.long) * t, detach=True, alpha=alpha, is_residual=True, is_vanilla=is_vanilla)\n",
    "        else:\n",
    "            score_fn = self.get_score_fn(input, torch.ones((x_num * y_num,), device=device).type(torch.long) * t, detach=True)\n",
    "            \n",
    "        score_fn_x = score_fn[:, 0].cpu().numpy().reshape(x_num, y_num)\n",
    "        score_fn_y = score_fn[:, 1].cpu().numpy().reshape(x_num, y_num)\n",
    "        plt.quiver(x, y, score_fn_x, score_fn_y, color='r')\n",
    "        plt.title('Score Function')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        if save:\n",
    "            plt.savefig(f\"{file}\")\n",
    "\n",
    "    # Resets the total loss and respective count of updates\n",
    "    def reset_loss_count(self):\n",
    "        self.total_loss = 0\n",
    "        self.loss_counter = 0\n",
    "\n",
    "    def update_loss_dict(self, loss):\n",
    "        if not self.loss_dict:\n",
    "            self.loss_dict.update({'DSMloss': [loss]})\n",
    "        else:\n",
    "            self.loss_dict['DSMloss'].append(loss)\n",
    "    \n",
    "    def get_loss_dict(self):\n",
    "        return self.loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b321c5b-8abd-4d00-b18c-c38beb91999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lp_dist(p=2):\n",
    "    return nn.PairwiseDistance(p=p, keepdim=True)\n",
    "# def move_metric_x_to_device(self, metric_x, device):\n",
    "# metric_x.to(device)\n",
    "def compute_gp_loss(x, z, dist_func_x, dist_func_z):\n",
    "    batch_size = len(x)\n",
    "    loss = 0\n",
    "    for idx in range(batch_size-1):\n",
    "        p_dist_x = dist_func_x(x[idx], x[idx+1:]).squeeze()\n",
    "        p_dist_z = dist_func_z(z[idx], z[idx+1:]).squeeze()\n",
    "        loss += ((p_dist_x-p_dist_z)**2).sum()\n",
    "    return loss/(batch_size-1)\n",
    "\n",
    "def pairwise_distances(x, y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "    y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "    if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "        dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "        # Ensure diagonal is zero if x=y\n",
    "    if y is None:\n",
    "        dist = dist - torch.diag(dist.diag())\n",
    "    return torch.clamp(dist, 0.0, np.inf)\n",
    "\n",
    "def calculate_gp_loss(X_list, Z_list):\n",
    "    loss = 0\n",
    "    for X, Z in zip(X_list, Z_list):\n",
    "        loss += torch.sum(torch.abs(pairwise_distances(X)-pairwise_distances(Z)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be4d35-bb2a-4c3b-88c5-2263312ed28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display reconstructed images\n",
    "def display_reconstructed_images(epoch, vae_model, data, n_samples=10, dim=[1, 28, 28], is_flip=False):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)[:n_samples]\n",
    "        recon_x, z, _, _ = vae_model(data)\n",
    "        recon_x = recon_x[:n_samples]\n",
    "        comparison = torch.cat([data.view(-1, dim[0], dim[1], dim[2]), recon_x.view(-1, dim[0], dim[1], dim[2])])\n",
    "        comparison = make_grid(comparison, nrow=data.size(0))\n",
    "        comparison = comparison.cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.imshow(comparison, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Reconstructed Images at Epoch {epoch}')\n",
    "        plt.show()\n",
    "\n",
    "def display_reconstructed_and_flip_images(epoch, vae_model, flip_vae_model, data, n_samples=10, dim=[1, 28, 28], flip_dim=[3, 32, 32], is_mnist=True, is_both=True):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)[:n_samples]\n",
    "        recon_x, z, _, _ = vae_model(data)\n",
    "        recon_x_flip = flip_vae_model.decode(z)\n",
    "        data = data[:n_samples]\n",
    "        recon_x = recon_x[:n_samples]\n",
    "        recon_x_flip = recon_x_flip[:n_samples]\n",
    "\n",
    "        data = data.view(n_samples, dim[0], dim[1], dim[2])\n",
    "        recon_x = recon_x.view(n_samples, dim[0], dim[1], dim[2])\n",
    "        recon_x_flip = recon_x_flip.view(n_samples, flip_dim[0], flip_dim[1], flip_dim[2])\n",
    "        z = z[:n_samples]\n",
    "        fig, axes = plt.subplots(3, n_samples, figsize=(n_samples * 3 / 2, 4.5))\n",
    "        if is_mnist:\n",
    "            main_color = 'gray'\n",
    "            flip_color = None\n",
    "        elif is_both:\n",
    "            main_color = 'gray'\n",
    "            flip_color = 'gray'\n",
    "        else:\n",
    "            flip_color = 'gray'\n",
    "            main_color = None\n",
    "            \n",
    "        for i in range(n_samples):\n",
    "            axes[0, i].imshow(np.transpose(data[i].detach().cpu().numpy(), (1, 2, 0)), cmap=main_color)\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(np.transpose(recon_x[i].detach().cpu().numpy(), (1, 2, 0)), cmap=main_color)\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            axes[2, i].imshow(np.transpose(recon_x_flip[i].detach().cpu().numpy(), (1, 2, 0)), cmap=flip_color)\n",
    "            axes[2, i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1703c-6646-4807-8327-cece56a8b03d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461039cd-4da9-4c1a-a850-3a8dab6ae3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Define the transformation to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Download and load the training dataset\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test dataset\n",
    "test_dataset = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Define a simple ResNet-like architecture for the classifier\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional layer (sees 1x16x16 image tensor)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(128 * 2 * 2, 256)  # assuming the input is (1, 16, 16)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 2 * 2)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize classifier, optimizer, and learning rate scheduler\n",
    "classifier = CNN().to(device)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training function\n",
    "def train_classifier(classifier, device, train_loader, optimizer, epoch):\n",
    "    classifier.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)}'\n",
    "                  f' ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Test function\n",
    "def test_classifier(classifier, device, test_loader, preprocess_model=None):\n",
    "    classifier.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = classifier(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)}'\n",
    "          f' ({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n",
    "\n",
    "# Train and evaluate the classifier\n",
    "# num_epochs = 100\n",
    "# for epoch in range(1, num_epochs + 1):\n",
    "#     train_classifier(classifier, device, train_loader, optimizer, epoch)\n",
    "#     test_classifier(classifier, device, test_loader)\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f721a-f01f-4efa-a0d6-8c11de0c06ac",
   "metadata": {},
   "source": [
    "## Domain Adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e0833-6e84-4685-8736-2b2bab67a631",
   "metadata": {},
   "source": [
    "#### MNIST and MNIST Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64399fb9-4626-466f-ac4c-e6ac765cd079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c214c2-29ab-4aa9-83bb-87be42c54a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Model, optimizer\n",
    "batch_size = 1024\n",
    "timesteps = 100\n",
    "is_vanilla = True\n",
    "mnist_input_dim = 1 * 28 * 28\n",
    "flip_mnist_input_dim = 1 * 28 * 28\n",
    "hidden_dim = 1024\n",
    "latent_dim = 256\n",
    "beta = 2\n",
    "sigma_max = 0.4\n",
    "sigma_min = 0.01\n",
    "loops = 1\n",
    "alpha = None\n",
    "gp_lambda = 0.05\n",
    "n_print_per_epoch = 1\n",
    "classifier_lambda = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the transformation to be applied to the images\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert images to PyTorch tensor\n",
    "])\n",
    "\n",
    "flip_mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Download and load the training dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, download=True, transform=mnist_transform)\n",
    "# flip_mnist_dataset = datasets.flip_mnist(root='./data', split='train', download=True, transform=flip_mnist_transform)\n",
    "flip_mnist_dataset = datasets.MNIST(root='data', train=True, download=True, transform=mnist_transform)\n",
    "\n",
    "# Create a DataLoader\n",
    "mnist_dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "flip_mnist_dataloader = DataLoader(flip_mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "mnist_dataloader_score = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "flip_mnist_dataloader_score = DataLoader(flip_mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Setup Model\n",
    "# mnist_vae = VAE(mnist_input_dim, hidden_dim, latent_dim).to(device)\n",
    "# flip_mnist_vae = VAE(flip_mnist_input_dim, hidden_dim, latent_dim).to(device)\n",
    "mnist_vae = CNN_VAE().to(device)\n",
    "flip_mnist_vae = CNN_VAE().to(device)\n",
    "\n",
    "classifier = CNN().to(device)\n",
    "\n",
    "score_model = Score_fn(UNet(in_dim=latent_dim, out_dim=latent_dim, num_timesteps=timesteps, is_warm_init=False), sigma_min=sigma_min, sigma_max=sigma_max, num_timesteps=timesteps, device=device).to(device)\n",
    "# optimizer_vae = optim.Adam(chain(mnist_vae.parameters(), flip_mnist_vae.parameters()), lr=1e-3)\n",
    "optimizer_vae = optim.Adam(chain(mnist_vae.parameters(), flip_mnist_vae.parameters(), classifier.parameters()), lr=1e-3)\n",
    "optimizer_score = torch.optim.Adam(score_model.parameters(), 1e-4)\n",
    "\n",
    "# mnist_vae.load_state_dict(torch.load('cnn_mnist_vae_test.pth'))\n",
    "# flip_mnist_vae.load_state_dict(torch.load('cnn_mnist_flip_vae_test.pth'))\n",
    "# score_model.load_state_dict(torch.load('cnn_score_model_test.pth'))\n",
    "# classifier.load_state_dict(torch.load('cnn_classifier_test.pth'))\n",
    "\n",
    "total_loss_list = []\n",
    "recon_loss_list = []\n",
    "kl_loss_list = []\n",
    "gp_loss_list = []\n",
    "\n",
    "# Training\n",
    "num_epochs = 1500\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    mnist_vae.train()\n",
    "    flip_mnist_vae.train()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kld_encoder_posterior = 0\n",
    "    total_kld_prior = 0\n",
    "    total_gp_loss = 0\n",
    "    total_classifier_loss = 0\n",
    "    for i, (data1, data2) in enumerate(zip(mnist_dataloader, flip_mnist_dataloader)):\n",
    "        x1, label1 = data1\n",
    "        x2, label2 = data2\n",
    "        # x1, x2 = x1.to(device).view(x1.shape[0], -1), (1.0 - x2).to(device).view(x2.shape[0], -1) # Reshape\n",
    "        # x1, x2 = (1.0 - x1).to(device).view(x1.shape[0], -1), (x2).to(device).view(x2.shape[0], -1) # Reshape\n",
    "        x1, x2 = (1.0 - x1).to(device), x2.to(device) # Reshape\n",
    "        optimizer_vae.zero_grad()\n",
    "\n",
    "        recon_x1, z1, mean1, logvar1 = mnist_vae(x1)\n",
    "        recon_x2, z2, mean2, logvar2 = flip_mnist_vae(x2)\n",
    "        # print(recon_x2.shape)\n",
    "        x, recon_x, z, mean, logvar = [x1.view((x1.shape[0], -1)), x2.view((x1.shape[0], -1))], [recon_x1, recon_x2], torch.vstack((z1, z2)), torch.vstack((mean1, mean2)), torch.vstack((logvar1, logvar2))\n",
    "\n",
    "        # Score loss\n",
    "        DSM = score_model.get_LSGM_loss(z, is_mixing=True, is_residual=True, is_vanilla=is_vanilla)\n",
    "        score = score_model.get_mixing_score_fn(z, 30*torch.ones(z.shape[0], device=device).type(torch.long), detach=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha) - 0.05 * z\n",
    "        score = torch.matmul(score.unsqueeze(1), z.unsqueeze(-1)).sum()\n",
    "\n",
    "        # VAE loss\n",
    "        loss, recon_loss, kld_encoder_posterior, kld_prior = vae_loss(recon_x, x, mean, logvar, beta, score=score, DSM=None)\n",
    "\n",
    "        # dist_func_x = get_lp_dist(p=2)\n",
    "        # dist_func_z = get_lp_dist(p=2)\n",
    "        # gp_loss = sum([compute_gp_loss(x, z, dist_func_x, dist_func_z) for x, z in zip([x1, x2], [z1, z2])])\n",
    "        gp_loss = gp_lambda * calculate_gp_loss([x1.view((x1.shape[0], -1)), x2.view((x1.shape[0], -1))], [z1, z2])\n",
    "        \n",
    "        # gp_loss_list.append(gp_loss.item())\n",
    "        \n",
    "        loss += gp_loss\n",
    "\n",
    "        output = classifier(z1.view((z1.shape[0], 1, 16, 16)))\n",
    "        label1 = label1.to(device)\n",
    "        classifier_loss = classifier_lambda * F.cross_entropy(output, label1, reduction='sum')\n",
    "        total_classifier_loss += classifier_loss.item()\n",
    "        \n",
    "        loss += classifier_loss\n",
    "        \n",
    "        total_loss_list.append((loss).item())\n",
    "        recon_loss_list.append((recon_loss).item())\n",
    "        kl_loss_list.append((kld_encoder_posterior+kld_prior).item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_vae.step()\n",
    "\n",
    "        total_gp_loss += gp_loss.item()\n",
    "        total_loss += loss.item()\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kld_encoder_posterior += kld_encoder_posterior.item()\n",
    "        total_kld_prior += kld_prior.item()\n",
    "\n",
    "        # Update Score Function\n",
    "        for loop in range(loops):\n",
    "            data1, data2 = next(iter(zip(mnist_dataloader_score, flip_mnist_dataloader_score)))\n",
    "            x1, label1 = data1\n",
    "            x2, label2 = data2\n",
    "            x1, x2 = (1.0 - x1).to(device), x2.to(device) # Reshape\n",
    "            # x1, x2 = x1.to(device).view(x1.shape[0], -1), (1.0 - x2).to(device).view(x2.shape[0], -1) # Reshape\n",
    "            # x1, x2 = (1.0 - x1).to(device).view(x1.shape[0], -1), (x2).to(device).view(x2.shape[0], -1) # Reshape\n",
    "            recon_x1, z1, mean1, logvar1 = mnist_vae(x1)\n",
    "            recon_x2, z2, mean2, logvar2 = flip_mnist_vae(x2)\n",
    "            x, recon_x, z, mean, logvar, labels = [x1.view((x1.shape[0], -1)), x2.view((x1.shape[0], -1))], [recon_x1, recon_x2], torch.vstack((z1, z2)), torch.vstack((mean1, mean2)), torch.vstack((logvar1, logvar2)), torch.vstack((label1, label2))\n",
    "\n",
    "            if loop == (loops-1) and (epoch+1) % n_print_per_epoch == 0 and i==0:\n",
    "                print(f\"Epoch {epoch+1} DSM average loss:\", end=' ') \n",
    "                score_model.update_score_fn(z, optimizer=optimizer_score, max_timestep=None, verbose=True, is_mixing=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha)\n",
    "                # score_model.draw_gradient_field((-0, 0), (-0, 0), t=0, x_num=40, yfl_num=40, data=z.detach().cpu(), labels=labels, save=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha, is_mixture=True)\n",
    "            else:\n",
    "                score_model.update_score_fn(z, optimizer=optimizer_score, max_timestep=None, is_mixing=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha)\n",
    "    # Print every 25 epochs\n",
    "    if (epoch + 1) % n_print_per_epoch == 0:\n",
    "        display_reconstructed_and_flip_images(epoch=epoch, vae_model=mnist_vae, flip_vae_model=flip_mnist_vae, data=x1, dim=[1, 28, 28], flip_dim=[1, 28, 28])\n",
    "        display_reconstructed_and_flip_images(epoch=epoch, vae_model=flip_mnist_vae, flip_vae_model=mnist_vae, data=x2, dim=[1, 28, 28], flip_dim=[1, 28, 28])\n",
    "        print(f'Epoch {epoch+1}, Total Loss: {total_loss:.2f}, Recon Loss: {total_recon_loss:.2f}, '\n",
    "              f'Encoder Posterior Loss: {total_kld_encoder_posterior:.2f}, Prior Loss: {total_kld_prior:.2f}, '\n",
    "              f'Total Gp loss: {total_gp_loss}, Total Classifier loss: {total_classifier_loss}')\n",
    "        # print(f'Epoch {epoch+1}, Total Loss: {total_loss:.2f}, Recon Loss: {total_recon_loss:.2f}, '\n",
    "        #       f'Encoder Posterior Loss: {total_kld_encoder_posterior:.2f}, Prior Loss: {total_kld_prior:.2f}'\n",
    "        #         )\n",
    "\n",
    "\n",
    "plt.plot(total_loss_list, label='total lost')\n",
    "plt.show()\n",
    "plt.plot(recon_loss_list, label='recon list')\n",
    "plt.show()\n",
    "plt.plot(kl_loss_list, label='kl list')\n",
    "plt.show()\n",
    "plt.plot(gp_loss_list, label='gp list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4a801-89b0-4231-9a9a-840bd2545903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Model, optimizer\n",
    "batch_size = 1024\n",
    "timesteps = 100\n",
    "is_vanilla = True\n",
    "mnist_input_dim = 1 * 28 * 28\n",
    "svhn_input_dim = 3 * 32 * 32\n",
    "hidden_dim = 1024\n",
    "latent_dim = 256\n",
    "beta = 2\n",
    "sigma_max = 0.4\n",
    "sigma_min = 0.01\n",
    "loops = 1\n",
    "alpha = None\n",
    "gp_lambda = 0.2\n",
    "classifier_lambda = 10\n",
    "n_print_per_epoch = 1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the transformation to be applied to the images\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert images to PyTorch tensor\n",
    "])\n",
    "\n",
    "svhn_transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Download and load the training dataset\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, download=True, transform=mnist_transform)\n",
    "svhn_dataset = datasets.SVHN(root='./data', split='train', download=True, transform=svhn_transform)\n",
    "\n",
    "# Create a DataLoader\n",
    "mnist_dataloader = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "svhn_dataloader = DataLoader(svhn_dataset, batch_size=batch_size, shuffle=True)\n",
    "mnist_dataloader_score = DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "svhn_dataloader_score = DataLoader(svhn_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Setup Model\n",
    "mnist_vae = VAE(mnist_input_dim, hidden_dim, latent_dim).to(device)\n",
    "svhn_vae = VAE(svhn_input_dim, hidden_dim, latent_dim).to(device)\n",
    "\n",
    "# Initialize classifier, optimizer, and learning rate scheduler\n",
    "classifier = CNN().to(device)\n",
    "\n",
    "score_model = Score_fn(UNet(in_dim=latent_dim, out_dim=latent_dim, num_timesteps=timesteps, is_warm_init=False), sigma_min=sigma_min, sigma_max=sigma_max, num_timesteps=timesteps, device=device).to(device)\n",
    "optimizer_vae = optim.Adam(chain(mnist_vae.parameters(), svhn_vae.parameters(), classifier.parameters()), lr=1e-3)\n",
    "optimizer_score = torch.optim.Adam(score_model.parameters(), 1e-4)\n",
    "\n",
    "# mnist_vae.load_state_dict(torch.load('svhn_mnist_vae_test.pth'))\n",
    "# svhn_vae.load_state_dict(torch.load('svhn_flip_vae_test.pth'))\n",
    "# score_model.load_state_dict(torch.load('svhn_score_model_test.pth'))\n",
    "# classifier.load_state_dict(torch.load('svhn_classifier_test.pth'))\n",
    "\n",
    "total_loss_list = []\n",
    "recon_loss_list = []\n",
    "kl_loss_list = []\n",
    "gp_loss_list = []\n",
    "classifier_loss_list = []\n",
    "\n",
    "# Training\n",
    "num_epochs = 1500\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    mnist_vae.train()\n",
    "    svhn_vae.train()\n",
    "    total_loss = 0\n",
    "    total_recon_loss = 0\n",
    "    total_kld_encoder_posterior = 0\n",
    "    total_kld_prior = 0\n",
    "    total_gp_loss = 0\n",
    "    total_classifier_loss = 0\n",
    "    \n",
    "    for i, (data1, data2) in enumerate(zip(mnist_dataloader, svhn_dataloader)):\n",
    "        x1, label1 = data1\n",
    "        x2, label2 = data2\n",
    "        label1 = label1.to(device)\n",
    "        x1, x2 = x1.to(device).view(x1.shape[0], -1), x2.to(device).view(x2.shape[0], -1) # Reshape\n",
    "        optimizer_vae.zero_grad()\n",
    "\n",
    "        recon_x1, z1, mean1, logvar1 = mnist_vae(x1)\n",
    "        recon_x2, z2, mean2, logvar2 = svhn_vae(x2)\n",
    "        x, recon_x, z, mean, logvar = [x1, x2], [recon_x1, recon_x2], torch.vstack((z1, z2)), torch.vstack((mean1, mean2)), torch.vstack((logvar1, logvar2))\n",
    "\n",
    "        # Score loss\n",
    "        DSM = score_model.get_LSGM_loss(z, is_mixing=True, is_residual=True, is_vanilla=is_vanilla)\n",
    "        score = score_model.get_mixing_score_fn(z, 30*torch.ones(z.shape[0], device=device).type(torch.long), detach=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha) - 0.05 * z\n",
    "        score = torch.matmul(score.unsqueeze(1), z.unsqueeze(-1)).sum()\n",
    "\n",
    "        # VAE loss\n",
    "        loss, recon_loss, kld_encoder_posterior, kld_prior = vae_loss(recon_x, x, mean, logvar, beta, score=score, DSM=None)\n",
    "\n",
    "        # Classifier loss\n",
    "        output = classifier(z1.view((z1.shape[0], 1, 16, 16)))\n",
    "        classifier_loss = classifier_lambda * F.cross_entropy(output, label1, reduction='sum')\n",
    "        loss += classifier_loss\n",
    "\n",
    "        dist_func_x = get_lp_dist(p=2)\n",
    "        dist_func_z = get_lp_dist(p=2)\n",
    "        gp_loss = sum([compute_gp_loss(x, z, dist_func_x, dist_func_z) for x, z in zip([x1, x2], [z1, z2])])\n",
    "        gp_loss = gp_lambda * calculate_gp_loss([x1, x2], [z1, z2])\n",
    "\n",
    "        classifier_loss_list.append(classifier_loss.item())\n",
    "        gp_loss_list.append(gp_loss.item())\n",
    "        \n",
    "        loss += gp_loss\n",
    "        total_classifier_loss += classifier_loss.item()\n",
    "        total_gp_loss += gp_loss.item()\n",
    "        total_loss_list.append((loss).item())\n",
    "        recon_loss_list.append((recon_loss).item())\n",
    "        kl_loss_list.append((kld_encoder_posterior+kld_prior).item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_vae.step()\n",
    "\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kld_encoder_posterior += kld_encoder_posterior.item()\n",
    "        total_kld_prior += kld_prior.item()\n",
    "\n",
    "        # Update Score Function\n",
    "        for loop in range(loops):\n",
    "            data1, data2 = next(iter(zip(mnist_dataloader_score, svhn_dataloader_score)))\n",
    "            x1, label1 = data1\n",
    "            x2, label2 = data2\n",
    "            x1, x2 = x1.to(device).view(x1.shape[0], -1), x2.to(device).view(x2.shape[0], -1) # Reshape\n",
    "            recon_x1, z1, mean1, logvar1 = mnist_vae(x1)\n",
    "            recon_x2, z2, mean2, logvar2 = svhn_vae(x2)\n",
    "            x, recon_x, z, mean, logvar, labels = [x1, x2], [recon_x1, recon_x2], torch.vstack((z1, z2)), torch.vstack((mean1, mean2)), torch.vstack((logvar1, logvar2)), torch.vstack((label1, label2))\n",
    "\n",
    "            if loop == (loops-1) and (epoch+1) % n_print_per_epoch == 0 and i==0:\n",
    "                print(f\"Epoch {epoch+1} DSM average loss:\", end=' ') \n",
    "                score_model.update_score_fn(z, optimizer=optimizer_score, max_timestep=None, verbose=True, is_mixing=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha)\n",
    "                # score_model.draw_gradient_field((-0, 0), (-0, 0), t=0, x_num=40, y_num=40, data=z.detach().cpu(), labels=labels, save=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha, is_mixture=True)\n",
    "            else:\n",
    "                score_model.update_score_fn(z, optimizer=optimizer_score, max_timestep=None, is_mixing=True, is_residual=True, is_vanilla=is_vanilla, alpha=alpha)\n",
    "    # Print every 25 epochs\n",
    "    if (epoch + 1) % n_print_per_epoch == 0:\n",
    "        display_reconstructed_and_flip_images(epoch=epoch, vae_model=mnist_vae, flip_vae_model=svhn_vae, data=x1, dim=[1, 28, 28], flip_dim=[3, 32, 32], is_both=False)\n",
    "        display_reconstructed_and_flip_images(epoch=epoch, vae_model=svhn_vae, flip_vae_model=mnist_vae, data=x2, dim=[3, 32, 32], flip_dim=[1, 28, 28], is_mnist=False, is_both=False)\n",
    "        print(f'Epoch {epoch+1}, Total Loss: {total_loss:.2f}, Recon Loss: {total_recon_loss:.2f}, '\n",
    "              f'Encoder Posterior Loss: {total_kld_encoder_posterior:.2f}, Prior Loss: {total_kld_prior:.2f}, '\n",
    "              f'Total Gp loss: {total_gp_loss}, Total Classifier loss: {total_classifier_loss}')\n",
    "        # print(f'Epoch {epoch+1}, Total Loss: {total_loss:.2f}, Recon Loss: {total_recon_loss:.2f}, '\n",
    "        #       f'Encoder Posterior Loss: {total_kld_encoder_posterior:.2f}, Prior Loss: {total_kld_prior:.2f}'\n",
    "        #         )\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        torch.save(mnist_vae.state_dict(), 'svhn_mnist_vae_test.pth')\n",
    "        torch.save(svhn_vae.state_dict(), 'svhn_flip_vae_test.pth')\n",
    "        torch.save(score_model.state_dict(), 'svhn_score_model_test.pth')\n",
    "        torch.save(classifier.state_dict(), 'svhn_classifier_test.pth')\n",
    "\n",
    "plt.plot(total_loss_list, label='total lost')\n",
    "plt.show()\n",
    "plt.plot(recon_loss_list, label='recon list')\n",
    "plt.show()\n",
    "plt.plot(kl_loss_list, label='kl list')\n",
    "plt.show()\n",
    "plt.plot(gp_loss_list, label='gp list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2fca6-cd54-4ce5-9d4e-857d334bba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mnist_vae.state_dict(), 'svhn_mnist_vae_test.pth')\n",
    "torch.save(svhn_vae.state_dict(), 'svhn_flip_vae_test.pth')\n",
    "torch.save(score_model.state_dict(), 'svhn_score_model_test.pth')\n",
    "torch.save(classifier.state_dict(), 'svhn_classifier_test.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
